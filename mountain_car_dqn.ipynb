{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "mountain_car_dqn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GhK1k82GGM_r"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucEQyRzDXS9p"
      },
      "source": [
        "Make sure you fill your name and NetID below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_NLdaL1XS9s"
      },
      "source": [
        "NAME = \"Sammy Berger\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDjqDzESXS9w"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1cphMJgSQS"
      },
      "source": [
        "# DQN for Mountain Car testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tR9-X4_gbb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78545f9e-7734-462d-97fb-f5ada9ee3d1b"
      },
      "source": [
        "### Setup:\r\n",
        "\r\n",
        "import gym\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "\r\n",
        "#this is mostly for pylSER\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "from keras.optimizers import Adam\r\n",
        "from collections import deque\r\n",
        "\r\n",
        "#should switch pylSER to GPU\r\n",
        "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 2 , 'CPU': 1} ) \r\n",
        "sess = tf.compat.v1.Session(config=config) \r\n",
        "tf.compat.v1.keras.backend.set_session(sess)\r\n",
        "\r\n",
        "#both this stuff and the things above it are for gkhayes\r\n",
        "!pip install 'gym[box2d]'\r\n",
        "!apt-get install python-opengl -y\r\n",
        "!apt install xvfb -y\r\n",
        "!pip install pyvirtualdisplay\r\n",
        "!pip install https://github.com/pyglet/pyglet/archive/pyglet-1.5-maintenance.zip\r\n",
        "!apt-get install ffmpeg -y\r\n",
        "\r\n",
        "# hopefully fix crash during rendering\r\n",
        "from pyvirtualdisplay import Display\r\n",
        "_display = Display(visible=False, size=(1400, 900))\r\n",
        "_ = _display.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.18.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[box2d]) (1.4.1)\n",
            "Collecting box2d-py~=2.3.5; extra == \"box2d\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]) (0.16.0)\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 1s (425 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8 [784 kB]\n",
            "Fetched 784 kB in 1s (629 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 147220 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-1.3.2\n",
            "Collecting https://github.com/pyglet/pyglet/archive/pyglet-1.5-maintenance.zip\n",
            "\u001b[?25l  Downloading https://github.com/pyglet/pyglet/archive/pyglet-1.5-maintenance.zip\n",
            "\u001b[K     - 17.3MB 7.1MB/s\n",
            "\u001b[?25hBuilding wheels for collected packages: pyglet\n",
            "  Building wheel for pyglet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyglet: filename=pyglet-1.5.11-cp36-none-any.whl size=1089584 sha256=0dcc006b2e976846dd8af0a39b6f7251abef9a73575e6ad382155f7c5b4436f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/bf/c6/31ad24e254cf2ffea48e575a12344c295076167cba5e4a208e\n",
            "Successfully built pyglet\n",
            "\u001b[31mERROR: gym 0.17.3 has requirement pyglet<=1.5.0,>=1.4.0, but you'll have pyglet 1.5.11 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "Successfully installed pyglet-1.5.11\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhK1k82GGM_r"
      },
      "source": [
        "## Using pylSER's algorithm:\r\n",
        "\r\n",
        "This is currently non-functional. Some updates to Python and its libraries since 2017 have rendered the implementation in its current state unusable.\r\n",
        "\r\n",
        "Original code: https://github.com/pylSER/Deep-Reinforcement-learning-Mountain-Car"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rV4jcJ2NGfxC",
        "outputId": "73e4d930-b088-43dd-f4db-ddabe9f8ea87"
      },
      "source": [
        "class MountainCarTrain:\r\n",
        "    def __init__(self,env):\r\n",
        "        self.env=env\r\n",
        "        self.gamma=0.99\r\n",
        "\r\n",
        "        self.epsilon = 1\r\n",
        "        self.epsilon_decay = 0.05\r\n",
        "\r\n",
        "        self.epsilon_min=0.01\r\n",
        "\r\n",
        "\r\n",
        "        self.learingRate=0.001\r\n",
        "\r\n",
        "        self.replayBuffer=deque(maxlen=20000)\r\n",
        "        self.trainNetwork=self.createNetwork()\r\n",
        "\r\n",
        "        self.episodeNum=400\r\n",
        "\r\n",
        "        self.iterationNum=201 #max is 200\r\n",
        "\r\n",
        "        self.numPickFromBuffer=32\r\n",
        "\r\n",
        "        self.targetNetwork=self.createNetwork()\r\n",
        "\r\n",
        "        self.targetNetwork.set_weights(self.trainNetwork.get_weights())\r\n",
        "\r\n",
        "    def createNetwork(self):\r\n",
        "        model = models.Sequential()\r\n",
        "        state_shape = self.env.observation_space.shape\r\n",
        "\r\n",
        "        model.add(layers.Dense(24, activation='relu', input_shape=state_shape))\r\n",
        "        model.add(layers.Dense(48, activation='relu'))\r\n",
        "        model.add(layers.Dense(self.env.action_space.n,activation='linear'))\r\n",
        "        # model.compile(optimizer=optimizers.RMSprop(lr=self.learingRate), loss=losses.mean_squared_error)\r\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=self.learingRate))\r\n",
        "        return model\r\n",
        "\r\n",
        "    def getBestAction(self,state):\r\n",
        "\r\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon)\r\n",
        "\r\n",
        "        if np.random.rand(1) < self.epsilon:\r\n",
        "            action = np.random.randint(0, 3)\r\n",
        "        else:\r\n",
        "            action=np.argmax(self.trainNetwork.predict(state)[0])\r\n",
        "\r\n",
        "        return action\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "    def trainFromBuffer_Boost(self):\r\n",
        "        if len(self.replayBuffer) < self.numPickFromBuffer:\r\n",
        "            return\r\n",
        "        samples = random.sample(self.replayBuffer,self.numPickFromBuffer)\r\n",
        "        npsamples = np.array(samples)\r\n",
        "        states_temp, actions_temp, rewards_temp, newstates_temp, dones_temp = np.hsplit(npsamples, 5)\r\n",
        "        states = np.concatenate((np.squeeze(states_temp[:])), axis = 0)\r\n",
        "        rewards = rewards_temp.reshape(self.numPickFromBuffer,).astype(float)\r\n",
        "        targets = self.trainNetwork.predict(states)\r\n",
        "        newstates = np.concatenate(np.concatenate(newstates_temp))\r\n",
        "        dones = np.concatenate(dones_temp).astype(bool)\r\n",
        "        notdones = ~dones\r\n",
        "        notdones = notdones.astype(float)\r\n",
        "        dones = dones.astype(float)\r\n",
        "        Q_futures = self.targetNetwork.predict(newstates).max(axis = 1)\r\n",
        "        targets[(np.arange(self.numPickFromBuffer), actions_temp.reshape(self.numPickFromBuffer,).astype(int))] = rewards * dones + (rewards + Q_futures * self.gamma)*notdones\r\n",
        "        self.trainNetwork.fit(states, targets, epochs=1, verbose=0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def trainFromBuffer(self):\r\n",
        "        if len(self.replayBuffer) < self.numPickFromBuffer:\r\n",
        "            return\r\n",
        "\r\n",
        "        samples = random.sample(self.replayBuffer,self.numPickFromBuffer)\r\n",
        "\r\n",
        "        states = []\r\n",
        "        newStates=[]\r\n",
        "        for sample in samples:\r\n",
        "            state, action, reward, new_state, done = sample\r\n",
        "            states.append(state)\r\n",
        "            newStates.append(new_state)\r\n",
        "\r\n",
        "        newArray = np.array(states)\r\n",
        "        states = newArray.reshape(self.numPickFromBuffer, 2)\r\n",
        "\r\n",
        "        newArray2 = np.array(newStates)\r\n",
        "        newStates = newArray2.reshape(self.numPickFromBuffer, 2)\r\n",
        "\r\n",
        "        targets = self.trainNetwork.predict(states)\r\n",
        "        new_state_targets=self.targetNetwork.predict(newStates)\r\n",
        "\r\n",
        "        i=0\r\n",
        "        for sample in samples:\r\n",
        "            state, action, reward, new_state, done = sample\r\n",
        "            target = targets[i]\r\n",
        "            if done:\r\n",
        "                target[action] = reward\r\n",
        "            else:\r\n",
        "                Q_future = max(new_state_targets[i])\r\n",
        "                target[action] = reward + Q_future * self.gamma\r\n",
        "            i+=1\r\n",
        "\r\n",
        "        self.trainNetwork.fit(states, targets, epochs=1, verbose=0)\r\n",
        "\r\n",
        "\r\n",
        "    def orginalTry(self,currentState,eps):\r\n",
        "        rewardSum = 0\r\n",
        "        max_position=-99\r\n",
        "\r\n",
        "        for i in range(self.iterationNum):\r\n",
        "            bestAction = self.getBestAction(currentState)\r\n",
        "\r\n",
        "            #show the animation every 50 eps\r\n",
        "            if eps%50==0:\r\n",
        "                env.render()\r\n",
        "\r\n",
        "            new_state, reward, done, _ = env.step(bestAction)\r\n",
        "\r\n",
        "            new_state = new_state.reshape(1, 2)\r\n",
        "\r\n",
        "            # # Keep track of max position\r\n",
        "            if new_state[0][0] > max_position:\r\n",
        "                max_position = new_state[0][0]\r\n",
        "\r\n",
        "\r\n",
        "            # # Adjust reward for task completion\r\n",
        "            if new_state[0][0] >= 0.5:\r\n",
        "                reward += 10\r\n",
        "\r\n",
        "            self.replayBuffer.append([currentState, bestAction, reward, new_state, done])\r\n",
        "\r\n",
        "            #Or you can use self.trainFromBuffer_Boost(), it is a matrix wise version for boosting \r\n",
        "            #self.trainFromBuffer()\r\n",
        "            self.trainFromBuffer_Boost()\r\n",
        "\r\n",
        "            rewardSum += reward\r\n",
        "\r\n",
        "            currentState = new_state\r\n",
        "\r\n",
        "            if done:\r\n",
        "                break\r\n",
        "\r\n",
        "        if i >= 199:\r\n",
        "            print(\"Failed to finish task in epsoide {}\".format(eps))\r\n",
        "        else:\r\n",
        "            print(\"Success in epsoide {}, used {} iterations!\".format(eps, i))\r\n",
        "            self.trainNetwork.save('./trainNetworkInEPS{}.h5'.format(eps))\r\n",
        "\r\n",
        "        #Sync\r\n",
        "        self.targetNetwork.set_weights(self.trainNetwork.get_weights())\r\n",
        "\r\n",
        "        print(\"now epsilon is {}, the reward is {} maxPosition is {}\".format(max(self.epsilon_min, self.epsilon), rewardSum,max_position))\r\n",
        "        self.epsilon -= self.epsilon_decay\r\n",
        "\r\n",
        "    def start(self):\r\n",
        "        for eps in range(self.episodeNum):\r\n",
        "            currentState=env.reset().reshape(1,2)\r\n",
        "            self.orginalTry(currentState, eps)\r\n",
        "\r\n",
        "\r\n",
        "#device = torch.device('cuda:0')\r\n",
        "env = gym.make('MountainCar-v0')\r\n",
        "dqn=MountainCarTrain(env=env)\r\n",
        "dqn.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2ea8c35673d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MountainCar-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMountainCarTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-2ea8c35673d0>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisodeNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mcurrentState\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morginalTry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-2ea8c35673d0>\u001b[0m in \u001b[0;36morginalTry\u001b[0;34m(self, currentState, eps)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m#show the animation every 50 eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestAction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     raise ImportError('''\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mcompat_platform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'darwin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcocoa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoaConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m  \u001b[0;31m# noqa: F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugwlJlyOJccS"
      },
      "source": [
        "## Using gkhayes's algorithm:\r\n",
        "\r\n",
        "This is the current best functioning DQN that attempts to learn Mountain Car that we have. It doesn't work that well, and reward never breaches about -150 over a short training period.\r\n",
        "\r\n",
        "This might be due to DQNs being particularly bad at learning to solve Mountain Car as proposed, or due to updates to Python/the packages used since this code was written. Credit goes to https://gist.github.com/gkhayes/3d154e0505e31d6367be22ed3da2e955/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ClWgaYwxJnHX",
        "outputId": "4c2366a2-dde5-4bfc-e0a6-40fa93f1fcf5"
      },
      "source": [
        "# Import and initialize Mountain Car Environment\r\n",
        "env = gym.make('MountainCar-v0')\r\n",
        "env.reset()\r\n",
        "\r\n",
        "# Define Q-learning function\r\n",
        "def QLearning(env, learning, discount, epsilon, min_eps, episodes):\r\n",
        "    # Determine size of discretized state space\r\n",
        "    num_states = (env.observation_space.high - env.observation_space.low)*\\\r\n",
        "                    np.array([10, 100])\r\n",
        "    num_states = np.round(num_states, 0).astype(int) + 1\r\n",
        "    \r\n",
        "    # Initialize Q table\r\n",
        "    Q = np.random.uniform(low = -1, high = 1, \r\n",
        "                          size = (num_states[0], num_states[1], \r\n",
        "                                  env.action_space.n))\r\n",
        "    \r\n",
        "    # Initialize variables to track rewards\r\n",
        "    reward_list = []\r\n",
        "    ave_reward_list = []\r\n",
        "    max_reward_list = []\r\n",
        "    \r\n",
        "    # Calculate episodic reduction in epsilon\r\n",
        "\r\n",
        "    \r\n",
        "    # reduction = (epsilon - min_eps)/episodes\r\n",
        "    reduction = (epsilon - min_eps)/100\r\n",
        "    \r\n",
        "    # Run Q learning algorithm\r\n",
        "    for i in range(episodes):\r\n",
        "        # Initialize parameters\r\n",
        "        done = False\r\n",
        "        tot_reward, reward = 0,0\r\n",
        "        state = env.reset()\r\n",
        "        \r\n",
        "        # Discretize state\r\n",
        "        state_adj = (state - env.observation_space.low)*np.array([10, 100])\r\n",
        "        state_adj = np.round(state_adj, 0).astype(int)\r\n",
        "    \r\n",
        "        while done != True:   \r\n",
        "            # Render environment for last five episodes\r\n",
        "            if i >= (episodes - 20):\r\n",
        "                env.render()\r\n",
        "                \r\n",
        "            # Determine next action - epsilon greedy strategy\r\n",
        "            if np.random.random() < 1 - epsilon:\r\n",
        "                action = np.argmax(Q[state_adj[0], state_adj[1]]) \r\n",
        "            else:\r\n",
        "                action = np.random.randint(0, env.action_space.n)\r\n",
        "                \r\n",
        "            # Get next state and reward\r\n",
        "            state2, reward, done, info = env.step(action) \r\n",
        "            \r\n",
        "            # Discretize state2\r\n",
        "            state2_adj = (state2 - env.observation_space.low)*np.array([10, 100])\r\n",
        "            state2_adj = np.round(state2_adj, 0).astype(int)\r\n",
        "            \r\n",
        "            #Allow for terminal states\r\n",
        "            if done and state2[0] >= 0.5:\r\n",
        "                Q[state_adj[0], state_adj[1], action] = reward\r\n",
        "                \r\n",
        "            # Adjust Q value for current state\r\n",
        "            else:\r\n",
        "                delta = learning*(reward + \r\n",
        "                                 discount*np.max(Q[state2_adj[0], \r\n",
        "                                                   state2_adj[1]]) - \r\n",
        "                                 Q[state_adj[0], state_adj[1],action])\r\n",
        "                Q[state_adj[0], state_adj[1],action] += delta\r\n",
        "                                     \r\n",
        "            # Update variables\r\n",
        "            tot_reward += reward\r\n",
        "            state_adj = state2_adj\r\n",
        "        \r\n",
        "        # Decay epsilon\r\n",
        "        if epsilon > min_eps:\r\n",
        "            epsilon -= reduction\r\n",
        "        \r\n",
        "        # Track rewards\r\n",
        "        reward_list.append(tot_reward)\r\n",
        "        \r\n",
        "        if (i+1) % 100 == 0:\r\n",
        "\r\n",
        "            max_reward = np.max(reward_list)\r\n",
        "            max_reward_list.append(max_reward)\r\n",
        "\r\n",
        "            ave_reward = np.mean(reward_list)\r\n",
        "            ave_reward_list.append(ave_reward)\r\n",
        "\r\n",
        "            reward_list = []\r\n",
        "            \r\n",
        "        if (i+1) % 100 == 0:    \r\n",
        "            print('Episode {} Average Reward: {}'.format(i+1, ave_reward))\r\n",
        "            \r\n",
        "    env.close()\r\n",
        "    \r\n",
        "    return ave_reward_list, max_reward_list\r\n",
        "\r\n",
        "# Run Q-learning algorithm\r\n",
        "avgs, maxs = QLearning(env, 0.2, 0.9, 0.8, 0, 10000)\r\n",
        "\r\n",
        "# Plot Rewards\r\n",
        "plt.plot(100*(np.arange(len(avgs)) + 1), avgs, label=\"average rewards\")\r\n",
        "plt.plot(100*(np.arange(len(maxs)) + 1), maxs, label=\"max rewards\")\r\n",
        "plt.xlabel('Episodes')\r\n",
        "plt.ylabel('Average Reward')\r\n",
        "plt.title('Average Reward vs Episodes')\r\n",
        "\r\n",
        "plt.show()\r\n",
        "#!gupload --to '1_F2AELuEcgPA3dV0gBJt746fiDkWBPmZ' plt.gcf()\r\n",
        "\r\n",
        "#plt.savefig('rewards.jpg')     \r\n",
        "plt.close()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 100 Average Reward: -200.0\n",
            "Episode 200 Average Reward: -200.0\n",
            "Episode 300 Average Reward: -198.2\n",
            "Episode 400 Average Reward: -199.57\n",
            "Episode 500 Average Reward: -196.17\n",
            "Episode 600 Average Reward: -190.4\n",
            "Episode 700 Average Reward: -186.37\n",
            "Episode 800 Average Reward: -190.22\n",
            "Episode 900 Average Reward: -189.18\n",
            "Episode 1000 Average Reward: -190.11\n",
            "Episode 1100 Average Reward: -154.8\n",
            "Episode 1200 Average Reward: -159.21\n",
            "Episode 1300 Average Reward: -177.81\n",
            "Episode 1400 Average Reward: -179.23\n",
            "Episode 1500 Average Reward: -155.31\n",
            "Episode 1600 Average Reward: -157.5\n",
            "Episode 1700 Average Reward: -178.49\n",
            "Episode 1800 Average Reward: -173.46\n",
            "Episode 1900 Average Reward: -165.74\n",
            "Episode 2000 Average Reward: -183.78\n",
            "Episode 2100 Average Reward: -164.95\n",
            "Episode 2200 Average Reward: -175.78\n",
            "Episode 2300 Average Reward: -176.07\n",
            "Episode 2400 Average Reward: -168.99\n",
            "Episode 2500 Average Reward: -160.72\n",
            "Episode 2600 Average Reward: -162.34\n",
            "Episode 2700 Average Reward: -156.9\n",
            "Episode 2800 Average Reward: -155.9\n",
            "Episode 2900 Average Reward: -162.0\n",
            "Episode 3000 Average Reward: -161.53\n",
            "Episode 3100 Average Reward: -159.35\n",
            "Episode 3200 Average Reward: -142.88\n",
            "Episode 3300 Average Reward: -142.26\n",
            "Episode 3400 Average Reward: -142.29\n",
            "Episode 3500 Average Reward: -148.15\n",
            "Episode 3600 Average Reward: -146.95\n",
            "Episode 3700 Average Reward: -145.21\n",
            "Episode 3800 Average Reward: -144.08\n",
            "Episode 3900 Average Reward: -144.55\n",
            "Episode 4000 Average Reward: -147.49\n",
            "Episode 4100 Average Reward: -147.83\n",
            "Episode 4200 Average Reward: -148.93\n",
            "Episode 4300 Average Reward: -138.9\n",
            "Episode 4400 Average Reward: -134.93\n",
            "Episode 4500 Average Reward: -131.65\n",
            "Episode 4600 Average Reward: -135.33\n",
            "Episode 4700 Average Reward: -132.29\n",
            "Episode 4800 Average Reward: -133.16\n",
            "Episode 4900 Average Reward: -135.4\n",
            "Episode 5000 Average Reward: -136.61\n",
            "Episode 5100 Average Reward: -132.64\n",
            "Episode 5200 Average Reward: -140.71\n",
            "Episode 5300 Average Reward: -143.52\n",
            "Episode 5400 Average Reward: -136.12\n",
            "Episode 5500 Average Reward: -136.41\n",
            "Episode 5600 Average Reward: -135.64\n",
            "Episode 5700 Average Reward: -136.09\n",
            "Episode 5800 Average Reward: -137.56\n",
            "Episode 5900 Average Reward: -131.28\n",
            "Episode 6000 Average Reward: -137.07\n",
            "Episode 6100 Average Reward: -133.67\n",
            "Episode 6200 Average Reward: -135.85\n",
            "Episode 6300 Average Reward: -136.44\n",
            "Episode 6400 Average Reward: -137.82\n",
            "Episode 6500 Average Reward: -136.02\n",
            "Episode 6600 Average Reward: -152.98\n",
            "Episode 6700 Average Reward: -148.17\n",
            "Episode 6800 Average Reward: -133.14\n",
            "Episode 6900 Average Reward: -131.02\n",
            "Episode 7000 Average Reward: -136.7\n",
            "Episode 7100 Average Reward: -136.62\n",
            "Episode 7200 Average Reward: -137.03\n",
            "Episode 7300 Average Reward: -133.9\n",
            "Episode 7400 Average Reward: -133.03\n",
            "Episode 7500 Average Reward: -135.5\n",
            "Episode 7600 Average Reward: -139.7\n",
            "Episode 7700 Average Reward: -133.17\n",
            "Episode 7800 Average Reward: -139.72\n",
            "Episode 7900 Average Reward: -125.97\n",
            "Episode 8000 Average Reward: -145.67\n",
            "Episode 8100 Average Reward: -137.82\n",
            "Episode 8200 Average Reward: -138.18\n",
            "Episode 8300 Average Reward: -134.42\n",
            "Episode 8400 Average Reward: -134.0\n",
            "Episode 8500 Average Reward: -136.0\n",
            "Episode 8600 Average Reward: -135.1\n",
            "Episode 8700 Average Reward: -129.45\n",
            "Episode 8800 Average Reward: -135.92\n",
            "Episode 8900 Average Reward: -131.88\n",
            "Episode 9000 Average Reward: -131.11\n",
            "Episode 9100 Average Reward: -138.05\n",
            "Episode 9200 Average Reward: -136.59\n",
            "Episode 9300 Average Reward: -134.42\n",
            "Episode 9400 Average Reward: -132.04\n",
            "Episode 9500 Average Reward: -140.07\n",
            "Episode 9600 Average Reward: -133.23\n",
            "Episode 9700 Average Reward: -132.54\n",
            "Episode 9800 Average Reward: -134.46\n",
            "Episode 9900 Average Reward: -132.21\n",
            "Episode 10000 Average Reward: -130.42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gc1fWw36PeJau5Se69V2xsjI0xYEIINqEbDCRACCUJCT9KAgn5gBQIafQeik3HQIBgio17792WbVnNVu9d2vv9cWellbQrrSyttLLu+zzz7M7MnZkzs9I9c8o9V5RSGAwGg8HgLj6dLYDBYDAYuhZGcRgMBoOhVRjFYTAYDIZWYRSHwWAwGFqFURwGg8FgaBVGcRgMBoOhVRjFYTB4MSKiRGRIZ8vhDBGZJSKHPHBer71ng8YoDoPbiMj3IpIvIoGdLUtbEZFHRKRaREpEpEBE1ovI2Z0tV0cjIjeJSK31HByXPi0dq5Rao5Qa3hFyGrwLozgMbiEiA4BZgAJ+5IHz+7X3Od3gPaVUGBALrAQ+6AQZgE67fzsblFJhjZaMTpTH4OUYxWFwl8XARuA/wI0AIhJova2PsTcSkTgRKReReGv9hyKy0+GtfpxD22QRuV9EdgOlIuInIg+IyFERKRaR/SKy0KG9r4g8JSI5InJcRO6y3Bp+1v5IEXlVRE6KSLqIPCYivi3dmFKqBlgC9BWRuJbOJSInRGSy9X2RJcNoa/2nIvKJ9f0sEdlg3ftJEXlGRAIc7keJyJ0icgQ4Ym37P6tthoj8xJXMInK1iGxttO0eEfnM+v4D6/kVW/Lf29JzcHGdZBF50DpXvoi8LiJB1r45IpLm0PZ+61rFInJIRM63tgeKyD+te8qwvgc6HOfynq1j/yYiKSKSKSIviEiwtS9WRD63nm+eiKwREdOndQDmIRvcZTG6c10CXCQiPZVSlcDHwLUO7a4CVimlskRkIvAa8DMgBngR+KyRq+ta4BIgyurAj6Itm0jgj8DbItLbansrcDEwAZgELGgk43+AGmAIMBG4ELilpRuzOvPFQC6Q78a5VgFzrO+zgWPAuQ7rq6zvtcA9aIvmbOB84I5Gl18ATANGich84F7gAmAoMK8Zsf8LDBeRoQ7brgOWWt9fBX6mlAoHxgArmjlXSywCLgIGA8OAhxo3EJHhwF3AVOuaFwHJ1u7fAdPRv9t44Cz7Ody4579Y15yA/i36Ar+39v0GSAPigJ7Ab9EWscHTKKXMYpZmF+AcoBqItdYPAvdY3+cBRx3argMWW9+fBx5tdK5DwGzrezLwkxauvRO4zPq+At0Z4nBtBfihO45KINhh/7XAShfnfQSoAgrQHXwuMMfa1+y5gJ8Cn1nfD6AVyrvW+glgkotr/gpY5rCugLkO668Bf3FYH2a1GeLifG8Dv7e+DwWKgRBrPQWtsCNaeL43oRVkgcPi+HsmA7c7rP/Avh+tPNOs70OALOs38W90jaPADxzWLwKSW7pnQIBSYLDD/rOB49b3/wd86ur5mMVzi7E4DO5wI/C1UirHWl9qbQMdGwgRkWlWHGQCsMza1x/4jeVKKBCRAiARcAy8pjpeSEQWO7i2CtBvy7HW7j6N2jt+7w/4Aycdjn0RiG/mvt5XSkWhFcVeYLKb51oFzLIsIV/gfWCmdf+RaGWHiAyzXCmnRKQI+JPDvTi7h8b3d6IZ2UH/DnZr7zrgE6VUmbX+Y3Qnf0JEVknzgf+NSqkoh2VwMzKeoOHvB4BSKgmtGB8BskTkXakPsPdpdC+O52junuOAEGCbw+/wlbUd4EkgCfhaRI6JyAPN3KOhHenMgJyhC2D5k68CfEXklLU5EIgSkfFKqV0i8j66A8sEPldKFVvtUoHHlVKPN3OJOteCiPQHXka7dDYopWpFZCf6zRPgJJDgcGyiw/dUtJUQq7TLy22UUjkichuwVUSWtnQupVSSiJQBdwOrlVJF1rO5DVirlLJZTZ8HdgDXKqWKReRXwBWu7t+6P8d76teC6N8AcSIyAf3873GQcQtwmYj4o11I7zc6d2toLJPTwLlSaimwVEQi0Ir2r8ANVvv+wD4n52junnOAcmC0UirdyfWK0e6q34iOs60QkS1Kqe9ad3uG1mIsDkNLLEC7ckahrYkJwEhgDTouAPrN92q0L3ypw7EvA7db1oiISKiIXCIi4S6uFYruSLMBRORmtMVh533glyLSV0SigPvtO5RSJ4GvgadEJEJEfERksIjMducmlVKHgOXAfW6eaxW6Q7bHM75vtA4QDhQBJSIyAvh5C2K8D9wkIqNEJAT4QwsyV6MzwZ4EotGKBBEJEB20j7TaFAE212dqkTtFJEFEotHxivcaNxCR4SIy14pfVaA7fPs13wEeEp04EYuOUbzd0j1bCvhl4B9Sn2zRV0Qusr7/UESGiIgAhei/07bcp8FNjOIwtMSNwOtKqRSl1Cn7AjwDLBIRP6XUJrQvug/wP/uBSqmt6ID2M+igcxLap+4UpdR+4ClgA9p6GYuOmdh5Gd2h70a/yX+J9s/XWvsXAwHAfut6HwK9cZ8ngdusTqqlc61CK4bVLtZBB32vQ8ceXsZJh+uIUup/wD/RsZwk3AtoL0XHFT5oZB3dACRbLrLb0UrdFWdL03EcUxtd42t0EsBR4DEn5whEB7JzgFNot96D1r7HgK3o320PsN1+Djfu+X5r+0brXr4F7GNHhlrrJei/meeUUiubuU9DOyFKmSQEQ9dERC4GXlBK9e9sWc5URCQZuEUp9W1ny2LwHozFYegyiEiw6PEJfiLSF+3WWNbScQaDoX0xisPQlRD02I58tKvqAPU5/QaDoYMwriqDwWAwtApjcRgMBoOhVZzx4zhiY2PVgAEDOlsMg8Fg6DJs27YtRykV52r/Ga84BgwYwNatW1tuaDAYDAZAF/Jsbr9xVRkMBoOhVRjFYTAYDIZWYRSHwWAwGFqFURwGg8FgaBVGcRgMBoOhVRjFYTAYDIZWYRSHwWAwGFrFGT+Ow9DFyT4Eez8Ce2mc6EEw/hoQaf44d1EKdr8PuUl6XQRGL4T4kQ3bJa+FYw5TbQyaDQPOadgm/wRkbNfHt5aaKtj1Doy8FEKiW3+8N3Lgc/179RzVcHuyVSl/wEzXxxakws4lYLMq5kclwsQb3Pvda2tgz/swbH77PsuTu6EoA4bPb9t5qitg93sw6jIIjmof2RqTshHStsLZd7bf/4oDRnEYvJf8ZHj9B1CWg65vaCmP0myY+Yv2ucbG52D5b60V6xpbXoFbvtWdHmil8eYCsFXXt1n/b7hrq+7QAGw2+OBGyNgBJdkw7Tb3ZVAK/vtL2LUUdi6FxZ+Cf1D73F9nsetdWPYzCI7WzzLGmo32xHp4a4H+vvhT6D+j6bH2Z5m+jQa/e2EanPfbpu0bs+11+PJeSJwGiz9rn2eZfQj+80OoLIQr34DRC07vPErBZ3fBng/0cv3H4BfQdvkcyTsG714HQVEw+SYIDGvf82NcVQZvpbwAllylO+s7t8AjBfD7fBi1AL75PRz4b9uvcfALWP47GPkjfe5HCuCubaBs+trl+ZCTBO8uguiBcH+ybvOrPfr47/5Yf67d72mlET0YvrofDi93X441f9NKY9h8SN2oO5auXHw0eR18epfuuFGw9Cooy4Pco7pDi+qnl3cX6W2N2fOBVhoLXtDP+w8FMPF6WPVXrZCaozwfVj4OPQZC6ib49A6tiNpCSTYsuVJ38H0na4WYdprVKL7/s76/YRdD8hr9wtCev3V5vv7bVTZY9IFHlAYYxWHwRmqr4f3FkHcUrn4b4obp7T4+sPAFSJgCH91qvZGeJhk74KNboO8kWPiiPjdA7BC4eom2dt69HpZeCT5+cN37ENxDt4nqBzPu1h1A6maoLNFKpM8k+Nkq6DUWPvwJnNrTshx7P4IVj8HYq+Dad2Huw/q83//59O+tM8lJgvcWQY8BcN17cM1SKEiB967XnS+iO7Tr3tft7UrFTlUpfPsI9JkI467W20Tgkn/AgFlaISWvwyWrntAvHVe/BfMe0c/3+z+d/v1Ul2tlV5IJ176n5Q7vBe9co12TrWHnO1r5TVgE174Dsx/QLwxr/nb68jlSUwXv3aD/dq9eUm/leYAzvqz6lClTlKlV1cVY+WdY9Re47DmY6GTG05JseGUuFGdCoDV9eWA4zPo1TLheK4HaGtj6Gmx4GqrKmp6jshjC4uGW7yC8Z9P9O9+BT24H30C46XNIPKvR8SXw9GSITIBBc/Q//0++hn7ToOgkvHI+lObUy+eK8nx97sWfgl+gfvv89E7t3w+JQbtq3CRhClz4GMQO1ev5yfDNH7SrzRlhPWHuQzD8Yt05V5XBun/C9je18gbwD4HpP4ezbgVf/6bnqCjUCsFuOVSVQkBIQ1ffrvdg2W3gG6BdR/3P1ttPbIA3fwRxw+HSf+m3eftvf/NX9e0cn9WrF+r7CozQ2wJCtRKffDPkH4fnpuuO+Uf/ttxCd8OOt2D6nTDnAQiyjju6Uiv7gtTmn2lttXZPXfWmjkkAZB+GV+fpff4h9c/yvN/CiEscnuW/rGdZZcmfB/1n1runlIKPb9PxmJDY5uVoTOI0uPDReuWQe1S7546ugIUvwfirW3e+RojINqXUFJf7jeIweB3vXKvf5u5Y77pN7lHY/HL9P+WpPZC2GXpPgKm36NhF1n7of47umBrj6w9Tb9UWhit2v687hEGzne/fsUS7QhAYczlc8Vr9vuzDOlZiq3F+rJ3AcJj5y4ZB3Joq3ekUn2z+WEds1bDvU6guhWm3g38wrPu3tpZGL9RKqTEn1kH2QRg8VwflVz8FRWnajRLRR7fJOaxdKrHD4eK/6LaOfP0QrH8GJt0APv7g46uD2L3HNWy350OtCAef13D7of/BZ7+A0iwYdw3s/1QHn6/8j/P7LEiBjS9ATYVezz6o7yN+tH6WmfvgF9v1SwHozv3Le2HbGxAaB7Pvg2Pfw8HPtVU0eC4tKueB5zaNaaRv1/EoZbnBTqyH7AMw6DytYNY8BYWp2v0Y0Ve3CYrQv7XdcgWoqYS1/9QWjbvUVsG+T/QzOPsOEF/Y8IxWzBf8Uf/9txGjOIzi6Hq8fgmg4OYv3T9GKe2W+PphKM7Q7qSL/lz/BugJbDZ4eY4OnN61RV+zMynJhhX/D7a/BSjt/rrgj/VKoDG11bDlVVj5J/1W3WssXPxEw4C1UnD4K/jqAf2mf/ETMO1nel/uUXh2mn67vezZ05e7oghWPwkbnwfx0c+yh5vTyCul413LfweFKTDvj3DOr5q2S98O/7tfv1z4h8C592orpL2SEGprYOurOr5SUQg9x8LFf20+c6wtFGdqi2nnEr0+/lrtmgvv1S6nN4rDKI6uxwuz9FvadS0EQp1RWaKDov1n6LduT1Oao98We472/LXcJeuAtnR6jXWvfWmOflMfcI62GJxRXaHjNof/p2Mxwy7Swe2jK/Ubfnt0WHnHdHyi76TWH1tdDsfXaAvC10WyqM0GKeu1C82VMm0r7jzL9iRzn1aevca062mN4jCKo+vxr/GQcBb8+OXOlsTgSFWpTo/OOaJjI8sf1MH8c+/tbMkM7UxLisNkVRm8j8ri+iCmwXsICNXWRnCUVhqR/fQAM0O3wygOg3ehlPZ5BxrF4ZVE9NYpqTFD4AdPdow70OB1mJHjBu+ipkJnCLWUxmroPHqNgbvbMIbG0OUxFofBu6gs1p/GVWUweC1GcRi8i4oi/WlcVQaD12IUh8G7qCzUn0ZxGAxei1EcBu/C7qoyMQ6DwWvpFMUhIleKyD4RsYnIlEb7HhSRJBE5JCIXOWyfb21LEpEHOl5qQ4dgd1WZGIfB4LV0lsWxF7gcWO24UURGAdcAo4H5wHMi4isivsCzwMXAKOBaq63hTKPO4jCKw2DwVjolHVcpdQBAmtYQugx4VylVCRwXkSTAXpY0SSl1zDruXavt/o6R2NBhVNqD48ZVZTB4K94W4+gLONY5TrO2udruFBG5TUS2isjW7Oxsjwhq8BAmq8pg8Ho8ZnGIyLeAs8pnv1NKfeqp6wIopV4CXgJdq8qT1zK0M5VFunqpq0J1BoOh0/HYf6dSat5pHJYOJDqsJ1jbaGa74Uyi0pQbMRi8HW9zVX0GXCMigSIyEBgKbAa2AENFZKCIBKAD6J91opwGT2EKHBoMXk+n+ANEZCHwNBAHfCEiO5VSFyml9onI++igdw1wp1Kq1jrmLmA54Au8ppTa1xmyGzxMRZEJjBsMXk5nZVUtA5a52Pc48LiT7V8CrZgSztAlMa4qg8Hr8TZXlaG7U1lsLA6DwcsxisPgXVQUmRiHweDlGMVh8C4qi42rymDwcoziMHgPtlqoMorDYPB2jOIweA9mEieDoUtgFIfBezAl1Q2GLoFRHAbvodLUqTIYugJGcRi8B2NxGAxdAqM4DN5D3SROkZ0rh8FgaBajOAzeg3FVGQxdAqM4DN6DmcTJYOgSGMVh8B7MfOMGQ5fAKA6D91BZDOKrJ3IyGAxei1EcBu+h0iqp3nQueoPB4EUYxWHwHkyBQ4OhS2AUh8F7MAUODYYugVEcBu/BTOJkMHQJjOIweA+VZtpYg6ErYBSHwXswMQ6DoUtgFIfBezAWh8HQJTCKw+A9mOC4wdAlMIrD4B1UV0BtlXFVGQxdAL/OFsBwhlBTCR/cBCWZTnYKzL4Phl3k+vi6kupGcRgM3o6xOAztQ+pmOPQliA8E92i45ByB7W82f7ypjGswdBmMxWFoH06sAwQWfQjBUQ33fXQrJK9p/viKQv1pguMGg9djLA5D+5C8FnqNbao0ABKmQPFJKEx3fbzdVWViHAaD12MUh6Ht1FRB2hboP9P5/r5T9Gf6VtfnMK4qg6HL0CmKQ0SuFJF9ImITkSkO2y8QkW0issf6nOuwb7K1PUlE/i1iSqh6DRnboaYCBrhQHL3GgG8ApDWnOMx84wZDV6GzLI69wOXA6kbbc4BLlVJjgRuBtxz2PQ/cCgy1lvkdIKfBHU6s05/9Zjjf7xeo3Vjp212fw8w3bjB0GTpFcSilDiilDjnZvkMplWGt7gOCRSRQRHoDEUqpjUopBbwJLOhAkbs3xadg/dPaJeWM5HUQNxJCY1yfo+8UyNgBtlrn+820sQZDl8GbYxw/BrYrpSqBvkCaw740a5tTROQ2EdkqIluzs7M9LOYZTmUJLLkCvn4IDv636f7aGkjd5NpNZSdhClSXQtYBF9cpAr9g8PVvu8wGg8GjeExxiMi3IrLXyXKZG8eOBv4K/Ox0rq2UekkpNUUpNSUuLu50TtF5lGTD0qsh92hnS6Ktg49+Cpn7ddB678dN25zaBVUl0N+Fm8pO38n601WA3BQ4NBi6DB4bx6GUmnc6x4lIArAMWKyUsvee6UCCQ7MEa9uZx+734PBXutO+/sPOlWX5b7UslzwFOUmw9VU93sIxDpFsxTdcZVTZiR6kBwOmb4PJNzXdX1ls3FQGQxfBq1xVIhIFfAE8oJRaZ9+ulDoJFInIdCubajHwaSeJ6Vn2fgQ+/pD0DRz5pvPkOPINbHoBpt8JU2+BMZfrWlIHv2zY7sQ6iB4M4b2aP5+ItjrStjnfbyZxMhi6DJ2VjrtQRNKAs4EvRGS5tesuYAjwexHZaS3x1r47gFeAJOAo8L+Oltvj5B3Xqa1z7tdv6Mt/B7XVnSNL9kH9Oed+/ZkwFSL7acVmx1YLJza0HN+w03cKZB/QcZPGFGdCWHzT7QaDwevorKyqZUqpBKVUoFKqp1LqImv7Y0qpUKXUBIcly9q3VSk1Rik1WCl1l5VddWaxz4ohjLsaLnwccg7B1tc7R5aKQl13KsByH4nA6AVwbCWU5eltO5dAZSEMmOXeOROmgLLp7KrGFGdARJ/2kd1gMHgUr3JVdXv2LoOEsyCqHwy/GAbOhu//VN9RdyQVhdp15OPwJzLmx2CrgQOfwfHV8Pk9MGgOjF7o3jn7TNKf6Y3cVdUVUJYL4UZxGAxdAZfBcRG5vLkDlVJOUmwMp032IcjcA/P/qtdF4II/wktz4ODnMGlxx8rTOAgO0Hu8dqFtfhkKUyFmCFz5hvsptKExWime2tNwe/FJ/RnRu+1yGwwGj9NcVtWl1mc8MANYYa2fB6wHjOJoT/Z+DAiMcshW7jVOl+rITep4eSoKmxYsFNFWx+onISQWrnvPeVHD5ugxAApSGm6rUxzG4jAYugIuFYdS6mYAEfkaGGVlNmGN4v5Ph0jXXVBKxzcGnNPwrdvHV3e0ecc6XqbyAuflPybeoAPi8x7RsrWWyH5w9LuG24qsYgHGVWUwdAnciXEk2pWGRSbQz0PydE+y9kPOYeexguhBkNsJisOZqwqgR3+4+QtInHp6541K1BZGTWX9NrviMK4qQztQUlnDolc2kpTlJHvP0C64ozi+E5HlInKTiNyEHmfxrWfF6mbYXVGJZzXdFz1YWxwdnUTmSnG0lchE/VnoUEGmKAMCwsw4DkO7sD+jiHVJuWw6ntvZopyxtKg4lFJ3AS8A463lJaXU3Z4WrFtR0cxcFNEDoaa8Pg7QYTIVQlAr4xfuEGUZq4Wp9duKMyC8t46hGAxtJC2/DIDcEhdFOQ1tptmSIyLiC+xTSo1AlwExeILKZkqKxwzWn3nHOi54XFutCxJ6RHFYFkeBg+IoOmkC44Z2Iy2/HIDcksoWWhpOl2YtDqVULXBIRExMw5NUNFNSPHqQ/uzIoof2+b894aqK6KsHFjpmVhWZwX+G9sNuceSUGovDU7hT5LAHsE9ENgOl9o1KqR95TKruRkWhHqHt49t0X2Sirl3VkZlVnlQcvv7aLWV3VdlsUHJKbzMY2gG7xZFTbCwOT+GO4njY41J0dyqbKSlel5LbkRZHgf701Gx8Uf3qXVWl2Xo0urE4DO1EnavKgxbH3vRCdqUVsGhaf49dw5tpUXEopVZ1hCDdGnt5D1fEDNYFEDtSHmj94D53iUyElI36e5FVHd8oDkM7UGtTnCz0fIzjqa8P8f3hbC4Z25uokACPXed0UUpRWWMjyN+JF6MdaDGryiplvkVESkSkSkRqRaTII9J0V5qzOEDHOToyJbfc0xZHolYYtTVm1LihXckqrqC6VhEXHkh+WTU1tbZ2v0ZZVQ3rjuaiFGw46p0pv3/7+hDXvLSR0soaj5zfnXEczwDXAkeAYOAW4FmPSNNdqWhhLoroQVBdpuf+7hB5PBjjAO2qUrVaaZhR4x4lp6SS5JzSlhu2MzW1Nh78eA+f787o0Ova3VTjE7S1nFfW/u6qNUdyqKrRCmltUo7TNjab4rsDmTy5/GBd247i2ZVJPLvyKCN7RxAS0EkWB4BSKgnwVUrVKqVeB+Z7RJruijsWB3RcnMPTisM+CLAgRSsOHz8I7TpT/H619xTvbk5puaEX8Ltle7j6pQ3YbB07gPTP/zvIO5tTeHFVx1Y9sGdUTUjUf7s5xe2vOL47kEl4kB/nDotjfSOLo9ameGdzChf8YxU/fWMrz648yoZjHWeVvLr2OE8uP8TCiX15fMEYxENjo9xRHGUiEgDsFJEnROQeN48zuIs7Fgd0XGZVRaHO5PIP8cz5HQcBFp/UGVU+XeNPqrCsmvs+3MXDn+6t86XbSc4p5Z3NKZRVecY90Fqqa22sPZJDZlEle9ILO+y6H21L49W1x+kTGcSe9EJOFVZ02LXT8vRvMs6yOHJL2zfOYbMpVhzMYs7weOYMi+N4TmmdsgJ4afUxHvx4D8EBvjx5xTj8fIRNbiqOrKIKLvrHar7a27xnwWZTTl8E3t+ayqOf7+fiMb148opx+Ph4bkCtO/+tN1jt7kKn4yYCP/aYRN2RyqLm3+7tKbkdNZbDXm7EUyO5I63p4wtSdayjC6XivrTmKEUVNdgUvLa2PmHBZlP88t0dPPjxHs59YiWvrDlGRXVts+dKyS1j4XPrGnQ87cmOlAJKq7QM3x3M8sg1GrM7rYAHl+1h+qBoXr5xinXtzFafp6rGRv5pZEWl5ZcTFx5I3x7BQPuPHt+ZVkBOSRXzRsYzc0gsAOuTtGKoqbXx5oZkZg6J4b93ncOVUxIZmxDJRjcUh82m+M0HuziUWczX+50rjmPZJTz+xX4mP/YNi1/bTGVN/d/X7rQCHlq2l1lDY/nXNRPx8/Xsi5g7Zx8CiFKqSCn1R6XUry3XlaE9qK7Qc3k356ry9dPFBTvM4nBRGbe98A+G0HgoTLFGjXcNxZFdXMnr65K5dHwffjiuN0s3pVBYpqf2/XRXOrvSCrljzmCG9wrnsS8OcP5Tq8gqcv22/craY+xIKWDloWyPyLvmSDY+AsN7hrPSieJo70k0lVLctXQHcWGBPHvdJEb1jiChRzDfHXBfaVXV2Fi6KYU5T65k1hMrOZHrOj5z6FQx8/+5mkyHZ5xWUEZCj2BiQwMBHeNpT77dn4mvjzBnWDzDeoYRGxZYF+f4Zn8mJwsruGnGwDoX0bSBMexOK2zRCn1t3XHWHMkhMtifnakFTfY/+PEe5j61itfXJTO6TyRrk3K494Pd2GyKwrJq7liyndiwAP59zUQC/DxvvbtzhcXALhHZKCJPisilItLD04J1G+zxhJYK/NmLHXYEnipw6EhUYn2MI6KvZ6/VTjz3fRKVNTbumTeUn507mNKqWt7amEx5VS1PfHWIsX0juffC4Sy5ZTpLbplGXmkVd72zw2lmT1FFNR9u04UedznpKNqD1UdymJAYxY8m9GFPemEDJfbWhmRmP/l9u1o7ReU1pOSVcdOMAcSEBSIizBvZk3VJOZRXNW99gc5QmvvU9/x22R7iI4IQgV+/v4taF/GZz3dncPBUcQPFlJZfTkKPECKC/fD3FXJaaXFkFlXw310Z7HXh2vv2QCZnDYgmMsQfEeGcITGsP5qDUoo3NiST0COYuSPi69pPGxRNjU2x/YTr33hveiF//eogF4zqya2zBnIsu5TC8uq6/QVlVby7JYVLx/dh/QNzefuWaTx48Qj+uyuDP315gN98sIvMogqeWTSJHqEdkxrsTpHDG5VSw4DLgVR0RpVnXpG6I83VqXKkI1NyO0JxRCZC5n5dE6sLuKrSC8pZsjGFKyYlMCgujFF9Ipg9LI7X14ZuCIQAACAASURBVCXzzMojnCys4KFLRtb5lWcOieXxhWPYfDyPv319uMn53t+SSllVLf1jQpy+YbaVgrIq9qQVMGtoXF1HtvKQ7mCLK6r529eHSckr4+dvb2/RpeYuGVbMp09UcN22eSN7Ulljc5l9ZKeiupZ7P9iFr4/w+s1TWXbHDB69bAzbTuTzwirnLtp11jnXHdWfNpsio6CcvlHBiAgxoYFuj+V4Zc0x5jy5kml/+o6739nBNS9t5NCp4gZtUnLLOJxZwrxRPeu2zRwSS05JFZ/tymDjsTxumN4fX4fYwpT+PfARXFbqLa2s4Rfv7iA6NIC//ngcExL1O/nutPq/ic3H81AKbpjen/iIIABuO3cQN80YwCtrj/PtgUwevHgkk/p13Pu8O+M4rheRF4EPgXno9NxZnhas29BcZVxHYgZ3XEqus9n/2puoflBqvSl2gTEcz6w4AsAv5g2t23b77MHkllbx7MqjzB/di2mDYhocc/mkBK49K5EXVh3l2/31fv5am+LNDSeY0r8HV0xK4Gh2CUUV1bQn64/mYlMwa2gsI3qF0ycyqO7N/D/rkiksr+aX5w9lT3ohf/h0X7tc054s0DsqqG7bWQOjCQ/047sDzcc53tyQTHpBOX++fCznDY9HRLhsQh8uGdubf357mH0ZDS2A4opqdqUV4iPaUrHZFFnFlVTXKhKs+EZMWIBbo8eTc0p5/MsDRIcG8NAlI3n7p9MICfDlJ//ZQlZxvZX2Xyu1eN7IeovCHuf4/af7CPTz4aopiQ3OHR7kz5i+kWw6ltfkukop7vtwN8k5pfzj6glEhwYwNkG/sDlaoRuP5RHo58P4xPqXORHh4R+OYtG0flw/vR83zxzQ4n22J+64qv4JTABeBn6hlHpCKbXBs2J1Iyrtqa8tuaoG6s+OcFd1iKvKoW6mlyuOnJJKPtqWzpVTEujr8DY9fVA04xOj8PcVHrh4hNNj/3DpaEb3ieCe93eywgoSrzyYRUpeGTfPHMj4xCiUgr1prct6qqiuZdmOND7Zkd6gc7Oz5kg24YF+jE+MQkQ4b0Q8a5NyyC2p5JW1x5k3Mp57LhjGnecN5r2tqbzTDunFGQVajj6R9c8owM+Hc4fF8d3BLJcpwQVlVTyzIonzhscxY3Bs3XYR4bEFY+gREsA97+1s4PLbfDyPWpti4cQE8kqrOJRZXOd2q1cc7lkcr6w9hr+PDy9cP5lbZg3inKGxvHrjVPJKq7j1ja1sO5HHTa9v5snlh5jUL4r+MaF1x/aJCmZQbCiF5dUsmNDXqato2sBodqYWNLHsXllznC/2nOS++SPq7jsy2J/BcaENrNCNx3KZ3L8HgX4Nx2T4+giPLxzLYwvGeizt1hXuuKpigZ8AQcDjIrJZRN7yuGTdBXctjmirvHpHzD/uatrY9iTS4c3My11V72xKoarW1uStTkT419UTeOPmsxgQG+r02CB/X164fjJ9o4L5yX+28tAne3h5zTF6RwZx4eiejLPeMHe4cFcppXh2ZRJPfX2ozvf+r2+PcM5fV3DPe7v41Xs7Oevx77jwH6t4Y30ySimUUqw+nMPZg2Pwt7Jrzh8ZT1lVLXcu3W5ZG8MA+PUFw5k1NJYHP97DVS9s4K2NJ5x2tkezS7j59c2k5rmOiZwsLMfPR4gLD2yw/fyR8WQXV7LbRdzg2ZVJlFTW8MDFI5vs6xEawO8vHcXhzJIGSQTrknIJ9PPh7rlDrPWcusF/CT10GnlsaECLMY7ckko+2JrGwol969xAAGMTIvnXNRPYnV7Ij5/fwI6UAh64eARLbpne5Bx2q2PxDOd1q6YPiqGq1saOlPrfeH1SDn/+3wEuHtOLn507qEH78YlR7EwtRClFQVkVB04VMb2RNdvZtFirSkQi0FPF9gcGAJFAxw6FPJOpi3G0oDii+kNIDJxYB5Nv9Jw81RVQW9kxwXE7Xqw4qmttvLXxBLOGxjIkvmnZ+wGxoS6Vhp3E6BA+uXMmTy4/xKtWCu9984fj7+tDVEgAA2NDXQbI0/LLeXL5oSbb546I55ZZA4kI8mddUg7f7M/kD5/t4+CpYn4ycwDpBeXcPmdwXfsZg2MJ8vdh47E85o3sWecS8fURnls0idfXJfPZrgwe/mQvj36+n0cvG83VU7VVmJpXxqKXN3GqqIItyXkkRjsf33OyoIKeEUENfPwA5w2Px0fgD5/tIyEqmLKqGnqEBjB1QDT9Y0J4Y/0JrpicwPBeTqYVAOaP7kXPiEDe3niCC6z4wvqjOUwZ0IMBsaEMjA1l/dFcJvXT7lW7xREbHkhOSSVKKZdv5G9tPEFljY1bzx3YZN+Fo3vxj6smkJpXxo0zBxAR5O/0HHecN5gpA3owuo/z/5kpA6IR0ZbD2YNjOHSqmLvf2cGguDCevHJ8E9kmJkbx8fZ00gvK2Z9RhFJ0PcUBrHVYnlFKpbXQ3tAa3LU4fHxg8FxI+k6XIvfUgDlPjxq3Y7c4QmLAP6j5tp3I//aeIqu4kr/+eFybzhPk78vDPxzFnOFxfLw9nUVn1b+dTkiMYv1R58HjbSfyAVh2xwwC/Xw5ml3CyN7hDZTYmL6R3DprEH/7+hDPfX+Ub6x4yqwh9W6fIH9fZgyOZcXBLH7lEKcB7Yf/xflDuXvuEA6eKuZPXx7g/o/2sC+jiNvOHcSiVzZRaqWTZha5dv1kFJbTO7Lpb9kjNIDLJyWwLimHkopqQgL82JNeyMfb0y3ZfLjngmEuz+vn68M1U/vx7xVHSMktIyTQl4Onivm/i4YDMGNwDJ/sSKdHSACxYQF1hf1iQgOorLFRWlVLWGDTrq68qpY3N5zg/BHxTl8KABZMbDnjr3dkMJdNcN0uMtifUb0j2HQ8l1WHs7lzyXZCAnx58YbJTuUan6gV4K7UQradyG8S3/AG3KmOOw5AREKUUp4ZqdSdqSwCxL35todcAHs+gJM7oO9kz8hTpzg8HBwPitDX8PL4xuvrjjMgJoTZw9qnJMqsoXHMGtrwXOMTIlm2I51ThRX0atTxbknOIyzQj3EJUfj6CKP6OP878fER7ps/ggExofx22R4So4PpH9PQMrj3wuHMH9OLMX2dd0IiwsjeEbx+01T++tVBXl5znHc3p+LvKyy5dTo3vLKpwZiJxmQUVNR1eo3525XjG6wrpTiWU8qW43n0jgqmt0NcxBnXnJXI0yuOsHRzSt0zsLuIZg6JZcmmFL49kNnA+osJ0y6z3JLKug76rY0nqK6xWe6gAh3HaOQq8gTTBsbw5oZkfvKfLQzrGc5rN01xec8jekUQ4OfDztR8l/GNzsYdV9XZwKtAGNBPRMYDP1NK3eFp4boFFUV65j93LIgh5wMCR77t+ooDIH6kV7updqYWsCOlgD9cOsqj5Rvsne3O1HzmRzZ8HttO5DOxX1QT948rrpqaWNexNnaBjOoT4VLxOOLn68PvLhnF6D6RPLsyiUcXjGFCYhRxEYFku5gcyWZTnCqs4OIx7lmPIsLguDAGx4W51b53ZDDnj+zJB1tTmT08jvAgP8ZaCvDsQTGIQGF5dZ2bCnRWFUBOSRX9Y0LJKqrg4U/2Njjv+IRIpg2MdkuGtnDO0BheW3ec80fE8+9rJxLqxNKwE+Dnw+g+Eaw+nMPhrGLumefaGuss3M2qugjIBVBK7QLObctFReRKEdknIjYRmeJkfz+rjPu9Dtvmi8ghEUkSkQfacn2vorKFOlWOhMZCn4mQ9K3n5PH0JE6OXL0ELv2n569zmryxPpmwQD+umJzg0euM7B2Bv6+wM7Vh8LiwvJpDmcVM6d+6jm1M30iXVkVrWDCxL9/8enadf71neJBLiyO3tIqqWluDMRztzaJp/cgtreKTHelMHxRTp0x7hAYwqrf+H3JUHHEOFgfUJyC8cP1kXrxhMr+YO4THF3ZMRtJ5w+NZdscMXlo8pVmlYWdCYhSHMou9Mr4B7lfHTW20qa0jhvaiBxSudrH/78D/7Csi4oseeHgxMAq4VkRGtVEG76CisOXAuCNDL4D0rVDWNC+83eSBjlEcoTEdc53TZM2RbC4a3YtwF0HR9iLI35eRvSOaBMh3pOSjFEwZ4B2FGnpGBJLpJPUXHMZwOIlxtBfnDo0jMToYm4KZgxt2pna3lT2jChpaHKBrd/n7CnOGx3HR6F78+sLh7aJg3UFEmNivh9uW4wTLCg3y9774BrinOFJFZAagRMTfsgIOtOWiSqkDSqmmqSKAiCwAjgOOo5LOApKUUseUUlXAu8BlbZHBa2hp9r/GDLkAlA2OrvCQPFbn5ekBgF5ObkklOSVVjOztPGja3kxIjGJPemGD8hrbTuTj6yN1nUhn0zMiiMyiSqc1rurGcHjQ4vDxEa63pmqd1SjmNGuoVhyDHGIc0daYijqLIyWfUX0iPTYrXnti/829Mb4B7imO24E7gb5AOnowoEfiGyISBtwP/LHRrr7ocid20qxtrs5zm4hsFZGt2dleXh2lpbk4GtN3EgRHe85d5W7trDOcw5klAC5TRNub8QlRlFTWcDS7pG7bluQ8RvYOd8u10RHERwRRVWNrUEfJTkdYHAA/PWcgn999TpPYyDlDYvnw9rOZ4WCJBPr5Eh7kR25pFTW1NnanFTLRS5RwS/SLDmHqgB7NZmt1Ju4MAMxRSi1SSvVUSsUDdwM/b+k4EflWRPY6WZqzFB4B/qGUKmmmTYsopV5SSk1RSk2Ji/PyCYJamoujMT6+Vlrutzott93lKQS/IK9Oke0IDmfqOkXDe3aM4rC7o+yFD6trbexMLWh1fMOTxFsD+7KcBMhPFlYQ6OdT95bvKfx8fZy6l0TEGi/R0BUUF6bHchzKLKa8upaJ/bqG4hARPrh9RpMSJt6Cy1cZEUkEHgb6AMvQ7qE/oqvlvtPSiZVS805DnmnAFSLyBBAF2ESkAtiGngfETgLa+un6tNbiAB3n2PshnNqlg+VtQSm92LO6OmLUeBfgUGYxkcH+TUZBe4r+MaFcMzWR19Ye58eTEqiorqWi2uY18Q3QrirQFWSHNVKoGQV6DEdHl75oiZiwAHJLqupKeExM9J7n2ZVpzgZ+E1gFfISeKnYrsBMYp5TySKU9pVRd8UQReQQoUUo9IyJ+wFARGYhWGNcA13lChg5FKW1xtLajHmyl5X55H/zwH9BrjD7X7vdhxaM6lXb+n2CgG8lvKx6DfR/DXdu08uiIOlVuUlhWzed7MtifUYSfj+Dn68PguDCum9av5YPbyJHMYob3DO/QjvD++SNYvu8UD3+ylwtH6xHS3mRx9IzQStTZIECtODwX3zhdYkIDOZpdwo6UAmJCA0iM9j4ZuyLNKY5opdQj1vflInIlsEgp1Wb/iIgsBJ4G4oAvRGSnUuoiV+2VUjUichewHPAFXlNKtU9Jz86kpgJs1a2PJ4TFwcIX4KsH4cVZMGkxZB2A1E3QewKU58Ebl8Koy+CiP9XPuNeYnCRY90+w1UD2Aeg52lIcnWvO78so5OnvklhxMIuqWhuRwTqrqaK6lsoaG7OHxzUoNtjeKKU4dKqYH03o2MGJPUIDuH/+CB74eA9Hs0voGxXcZEBgZxIfXm9xNOZkYQVnD/a+tNGYsAA2J1exI0WPh/E2i6ir0mzUzZqwyf6kc4FIsZ68Uuq080GVUsvQ7q/m2jzSaP1L4MvTvaZXUuFmnSpnjL8Ghl4I3/8ZtryiS3dc9iyMv07Xmlr/NKz5u1YoP18Pvk5SSr95GHz8tOI4sb5ecYR0bgfw9HdJrDqczaLp/bh8YgJj+kYgIiRlFTPv76tZeTCL66c7LyjXHmQWVVJUUdPEHdMRXDUlkfe2prIjpYAFHay4WiI4wJeIIL8msxrW1NrILKpoUBXXW4gNCySvtIq80ioun+TZ8TjdieaC45Ho2IJ9iQC2W9+3el60boC9wGHgabqGQqLhB0/Cbw7BL3bCxOu1u8k/GGbfB1e8BjmHYetrTY89uhIOfQlzHtB1o5LX6u2enjbWDU4WljNlQA/+cOloxiZE1r0lDo4LIzE62Ok0qM6otSk2Hct1Wna8OQ5ZgfHOUBw+PrqUeICvD+cM9b7Ejp4RQU2C41nFldiUZ1NxT5fYsPpgvbekNZ8JuLQ4lFIDOlCO7kmFm3NxtERYvPPtwy+GgbO1VTL2Sq1oAGprYPlvdcXdaT/XVsnRFVbMpfNjHJlFlQx10mmLCHOHx/Pe1lQqqmubzcdPyirh/z7cVVfKekSvcGYPj+OOOUPqXF+uONKJigNgdJ9INv32/Bbl7AziIwKbuKqcTeDkLdjrVYlQV8Le0HY8P6t5dyRlI2x8oeV2nh4zIaJjHBWFsOoJva22RiuSrP1wwf/Tabf9Z0JpNuQc6ZjZ/5qh1qbILqmkV4TzTmjOiHgqqm1sPOZ8Ks5am+KFVUf5wb/XcDynlMcXjuH++SPoERLAy6uP8ejn+1uU4dCpYmLDAj2eWtocPUIDPFof63TRZUcaWhzOJnDyFmKs33BYfLjHKwB0J7xjZNGZxtbXdBXbCdc1b024OxdHW+g1BibdCFte1jGMjc9ppTHqMr2AVhwASd/oeEcnWhy5JZXU2lRdBk9jzh4UQ5C/DysPZjFneENLy2ZT3P/Rbj7clsb80b14dMGYunTan88ZzJ+/PMCLq49x/fT+zbotDmcWM7yXe8X3uhvxEUFkFVc0mOPCmy2OWOv37yrjN7oKxuLwBEUZuixI6qbm27k7F0dbOe934B8Cn90FVSVw9dtw5RvaIgE9n3lYTzho5R50ouI4ZblBerqwOIL8fZk5OJYVh7IalL6w2RS/XbaHD7el8cvzh/L89ZOajMG4a+4QYsMCeeSzfS6nMbXZFEeyShjqYn6G7k7PiECqaxX5ZfWjxzMKKggL9HM50VFn0icymD6RQcwb2bOzRTmjcEtxiMg5InKz9T3OGk9hcEWRntSeE+uab9cRFgfo9N3LX4YLH4c7N8PIS+uVBujv/WdAynpLns5THHY3iCvFAdpdlZpXXleeQynFQ5/u5d0tqdw9dwi/mjfUadpleJA/988fzs7UApbtcD5+NL2gnLKq2g4rNdLVcBwEaMc++M8bCQ7wZf2D5zNvlFEc7UmLikNE/oCuH/WgtckfeNuTQnVplKpXHMktKI4KaxKngA7opIbPhxl36YwrZ/Sfqa0k8AqLo7nxC3NHaBfVyoPZZBVX8NM3trJ0Uwo/nzOYX18wrNlc/R9PSmB8YhR/+eogeaVN56M+dKpzA+PejrOyIycLK+jthRlVBs/hToxjITARnYqLUipDRMx/lSsqCqCmXCuDjO1QVQYBVqnn2mrIOwZxesrLurk4PDUNbGuwxzmgUwcAZhZW4CM6/94VfaOCGd4znKWbU3h+1VFKK2t45NJR3DhjQIsDvHx8hEcuHcXlz69n0qPfMDA2lNF9IrjurH7MGBJbl4o7tKeJcTjDmcVxsrCc0W5MEGU4c3Cnx6pS2pmsAEQktIX23Zuik/pz5KU60Jy2uX7fqifg+RlQrOeE1uVGvOQfLm6ErroLneyqqiAuPLDFeQvOGxHP8ZxSekUE8fnd53DTzIFujwqe2K8Hy+6Yyb0XDmNYzzA2Hsvjulc2cd+Hu9h+Ip8+kUFe6a/3BuxxI/sgwNLKGnJKqryy3IjBc7hjcbwvIi8CUSJyK/AT4GXPitWFsbupxlwOu9/VI7IHzYHqCtj6qjVKe53e35rZ/zyNj4+Ocxz8vFMtjlNFFS5TcR35+ezBDIkP40fj+xDg13qLbUJiVF1mVUV1Lf/67ggvrT5GrU0xZ7j3DbzzFoL8fYkK8a+LRX17QL8ETR/kPTW1DJ7HnbLqfwM+RBc7HA78Xin1tKcF67IUW4ojdhj0Glcf59j3MZTlAlIfNG/t7H+eZvRCLXcnWhxZRZXEu6E4IkP8uWJywmkpjcYE+fty//wRfHrnTGYNjeXScd5V6sPbcJxCdtmOdPpEBjF1gFEc3Qm3xnEopb4BvvGwLGcGdldVeG8dN9jyCtRUwqYXtDsooo+2QkArjvDenSdrY8ZeoZdO5FRRBWcN7JxOaEzfSN766bROuXZXIj4ikKziSnJKKllzJIdbZw3yysGKBs/hTlZVsYgUNVpSRWSZiAzqCCG7FEXpEBoHfgEwYKYuOLjxOTi5C866DQacowfgleae3lwcZzAV1bUUlld7VUVYQ1Piw4PIKqrgi90nqbUpFkw0Flp3wx2L45/oqVqXoivlXgMMRmdZvQbM8ZRwXZLik/VWRL+z9efKP+lChuOvgVN79LaU9a2f/e8Mx+7+iO+gyZMMp0dPy+L4eEc6I3qFM6KX+RvubrjjIP6RUupFpVSxUqpIKfUScJFS6j3ATKfVmKKTEGHNExwSDfGjobYKJt0AAaHQZ5KemjV5nbE4GnGqsOUxHIbOp2dEEDU2xa7UAq+dE9vgWdxRHGUicpWI+FjLVYA9idt53YbuTFE6RDjELQbOAgSm3qLX/QIgYSoc/a7T60J5G5nFLY8aN3Q+jnXEOnqyK4N34I7iWATcAGQBmdb360UkGLjLg7J1Paor9Ox74Q7/TOfeBzd9AdEOVVoGnKPnyQDjqnIgs7D5OlUG78Ce9XbWwGiPzsRo8F5ajHEopY4Bl7rYvbZ9xeniFFsZVREOiiM0BkJnNmzXf0b9d2Nx1JFZVEGwv55lzuC99I8OIcDXh2umJna2KIZOosX/UBEJAn4KjAbqXgWVUj/xoFxdE/vgv4gWUmwTpoKP/+nNN34Gc6qogp4RgWZeaC8nJiyQzb87n6iQzpuvxNC5uOOqegvoBVwErAISgGJPCtVlqbM4WggY+gdD38n6u5PguGO58O5EZlGFcVN1EYzS6N64oziGKKUeBkqVUm8AlwBmlJQz7BaHO4P6Bljuq0YWR3pBOeMe+ZqtyXluX7asqsbl/BJdicyiSpNRZTB0AdxRHPYZWwpEZAwQCbiY5LqbU5QBAWHupdiOv1bPwBfdcAzlidxSiitreGPDCbcv+8On1/Kzt7d5rfJQSrVoRSmlLFeVURwGg7fjjuJ4SUR6AA8BnwH7gb96VCpv5pvfw/uLIfdo033FGQ0D480ROxSuelPP+e1AaWUtAMv3niLfyXwRjVFKcSK3jG/2Z/Lc90nuXbuDqKqx8cqaY4z749c8v8rJ83KgsLyaqhqbURwGQxegWcUhIj5AkVIqXym1Wik1SCkVr5R6sYPk8z4OfQX7P4XnpsO3j0ClQ7in6GSba0+VVdUAUFVr45Odzmepc6SksoZamyI8yI+nvjnM6sPZbbp+e7EuKYeL/7Wax744QFWNjf/uOtls+/opY82ocYPB22lWcSilbMB9HSRL16C6HIZcAGOugLX/gHeurd9X1AqLwwV2i6NvVDDvbUlt0cVTYM39fO+FwxneM5xfvLuD1LyyNsnQVnJKKrnp9c3U2hSv3TSFX84byoGTRQ0m/2mMvUy3OyXVDQZD5+KOq+pbEblXRBJFJNq+eFwyb6W6DKISYeHzcMGjkLwGMnaAzQYlp9pBcWiLY/HZ/Tl4qpjdaYXNtrcrjt6RQbxw/WSqa2z867sjbZKhrXx3IJPqWsWziyYxd0RPZg/T81s0Zw2ZwX8GQ9fBHcVxNXAnsBrYZi1bPSmUV1NdDv7WVLCTbwT/UNj0EpRm6xIibXRVlVquqmum9iPI34f3tqY2276gXMdBokICGBAbyojeEWQUlLdJhrayfF8mCT2CGdVbJwmM6h1BXHggq5pRHHZXVbxxVRkMXo87EzkNdLK0qZy6iFwpIvtExCYiUxrtGyciG6z9e6wBiIjIZGs9SUT+LZ0xSkwpbXH4W2UWgiJhwnWw90NdNh3axeIICfAlMsSfH4ztzWc7M+riHs6wWxw9QvRUp9GhAeS5EVT3FCWVNaxNyuHCUb3qBvKJCOcOjWNtUg61LjK/MosqiA4NINDPtyPFNRgMp4E783GEiMhDIvKStT5URH7YxuvuBS5HWzGO1/ID3gZuV0qNRpdst6cDPw/cCgy1lvltlKH11FQCql5xgJ5jo7YKvv+zXm+r4qiqJSRAD+i/akoiJZU1rDrk+k29oEwriUhLccSEBpDbiYpj1aFsqmpsXDS6Z4Pts4fHUVBWze60gibHKKU4klViyqkbDF0Ed1xVrwNVgL3AUjrwWFsuqpQ6oJQ65GTXhcBupdQuq12uUqpWRHoDEUqpjUpHi98EFrRFhtOi2go6211VAHHDYNB5kLFdr4e33eIIDdRv3SMtV096M64nu8URFaxH8kaHBpBfWtVpo8+/3n+K6NAApjSaSnTWkFhEcOqu+s/6ZDYfz2PBRFOi22DoCrijOAYrpZ7AevNXSpWhJ3TyBMMAJSLLRWS7iNgzuvqiJ5Oyk2Ztc4qI3CYiW0Vka3Z2O6anVlsduH+jiqDTbtefPn569r82UFpZS6hlcUQE+RHg50O2VW7cGQXl1YQG+NbNvR0dGkCNTVFU7tq91Z6sPpxdF9CvqrGx4mAW80bG49toKtEeoQGMS4hqoji2JOfx+BcHmDeyJ7fNMhNKGgxdAXcUR5VVQl0BiMhgwHVPZiEi34rIXifLZc0c5gecgy7lfg6wUETOd0PGBiilXlJKTVFKTYmLa1tH3oA6xRHScPvQC6DHAB0Y93HnkbqmrKre4hAR4sICyS5x/bjzy6oa1A2KDtXfc0tb/InazI6UfBa/tpnrXtlEQVkVG4/lUlxRw4WjejltP3tYHLtSC+oGNmYVVXDHku0kRofw96vHm3mrDYYugjv1qx8BvgISRWQJMBO4qaWDlFLzTkOeNGC1UioHQES+BCah4x4JDu0S0C6zjqXOVdXI4vDxhQUvQFlOmy9RWllDj9B6RRAbHtisxVFYVk1ksH/dul1x5Jd5Ps6xI0XHK/ZnFHLNSxsZHBdGSIAv5wyNddp+9rA4/v3dEZ5ekUR5dS0rDmZSUlHD2z+dRkSQv9NjDAaD9+HOfBxf6IB63wAAGO5JREFUi8g2YDraRfVLe8fuAZYD94lICDquMhv4h1LqpIgUich0YBOwGHjaQzK4xpWrCqD/2e1yidKqWhJ61P8scWEBpBe4HjhXUF5Nj9D6TjcmVAeYc0s8rzh2pxXQMyKQv105ntve3MbBU8X8YGwvgvydZ0aNT4gkKsSf19YdJyzQjxmDY7h55kCG9wr3uKwGg6H9cGc+jv8CS4HPlFKl7XFREVmI7vjjgC9EZKdS6iKlVL6I/B3YgnaNfamU+sI67A7gP0Aw8D9r6VicBcfbGXs6rp248EB2proeBJhfVsXIXvVFFaPDtMXRESm5u9MKGZcQxayhcbz107P4zQe7uPasfi7b+/n6sOSWaZRV1TIhMQp/37a59QwGQ+fgjqvqb+hBgH8RkS3Au8DnSinXr8EtoJRaBixzse9ttGuq8fatwJjTvWa70JzF0U7orKr6nyU2LJC80kpqbapJwBksV1WIo8Vhj3F4VnEUlldzLKeUyyfpHIUpA6JZ9X/ntXjc6D5mxkODoavjzgDAVUqpO4BBwIvAVej5x7sfHrY4lFKUVdXWBcdBWxw25dyCUEppV5WD4gjy9yUkwNfjFsfedG0FjUuI8uh1DAaD9+GWr8DKqvoxcDswFXjDk0J5LR62OCprbNTYVBOLA3ThwMbYK+Pax3DY6RHi+dHju6yBfOMSjAVhMHQ33Bk5/j5wAJgLPIMe13G3pwXzSlyl47YTZVW6Mq59HAdoiwNwmlllH/zn6KoCiAk7vdHjW5Pz+NW7O9yaEGp3aiH9Y0LMFKIGQzfEHYvjVbSyuF0ptRKYISLPelgu78RVOm47YR9I5xgcb87iqK9T1bDz1vWqXKfwniqsqHM1OfLdwSw+2ZnR7Eh1O7vTCoybymDoprgT41gOjBORJ0QkGXgUOOhpwbwSu8Xh5yHFYRUzDAt00+Koq4zb0OLQZUeqm7S38+jn+/nZW9uabM+xrpGUVdKsnNnFlWQUVjDeuKkMhm6Jy6wqERkGXGstOcB7gCilWk6dOVOpLgO/oDaPDndFncXhoDhCA3wJ8vdxanHk19WpauSqCg1wOXJcKcWW5DxyS6uaZGrZr3E0u4TzRrieVn5Puj2+YSwOg6E70lwPeBAd1/ihUuocpdTTQG3HiOWl1FRoxeEh7LP/hTlkVYkIcS5GjxeW1c/F4Uh0aCAV1Tan5dgzCivIKtbpvY0D6DnWoMGWLI5dqYX4CIzpG9FsO4PBcGbSnOK4HDgJrBSRl62aUd27mFB1mUcH/9k7+pCAhoZgrIt6VXXBcScWBzgfPb79RH7d98bKyL5+NLt5xbE7rYCh8eFN5DQYDN0Dl4pDKfWJUuoaYASwEvgVEC8iz4vIhR0loFdRXe7RwX8llU2zqgDiwgLJKW6qBPLLGlbGtWOvdeUsJddeXwpooIyUUnXureYsDqWUNWLcxDcMhu6KO8HxUqXUUqXUpejigjuA+z0umTfiOG2sB7BbHI4DAMEqdOjM4iivcpoOG92M4tiekk8va15vR4ujsLya6lpF36hg8suqXY4DSS8oJ7e0inGJJr5hMHRXWhXlVUrlWyXLW13q/IzAcdpYD1BSaVccTS2O/LIqqmttDbYXllU3yagC12VHKqpr2ZdRyIXW7HxZxfVVY+xKZNogPQGTK3fVdstimWAC4wZDt8VUmWsNHnZVlVXW4usjBDZyPcWFB6KclB0pKHeuOOyFDvMbtd+XUUR1rWLG4FjCAv0aWBx2i2b6oBjAtbtq8/FcwgL9GNnbVLQ1GLorRnG0Bg8Hx0urdGVckYY5CPZBgI2D2Y0ncbITHuj3/9u78+i6yzqP4+9v9jZJs7RJCV1oS8tSoNI21jKgCFQo6OAM4qGI2yjDMNYzojPj0MEZ5eg54zieUVFmhIMgOsgiyiKorC5QpQuLpSsNbeli26R0zdIkN3nmj9/zS39J701/N83NTW8+r3Pu6e8+z+/ePM/9pfebZ/k9D4X5dlSL49WtwcD4nFMqj5qpFc6oesfESooL8ngzZeDYy9xTqijQyrYiI5b+96cjwy2OlvbEUQPjELkJsM84x4HWzqPu4YBgCm+yu8df2bqPiVWjqC0voaa8mMZo4PDH48cUM62mjIYkXVX7Wjp4Y3cz86ZWH5UnIiOHAkc6Mjw43tJnZdxQTbjsyKHes6BSdVVBcC9H366tV7fuZ/bkquA9y4t7vV9TczuF+UbFqEJOrSlNOsaxYsteAN6lwCEyoilwpCPDg+N99+IIjSsPuqOiLY5DKVbGDVWXFvbqqtp5oI2dBw4zZ3IwqF1T1qer6lA7Y0uLMTOm15axfV8bhzt73++5fPNeigryOEdTcUVGNAWOdAzB4HiyrqrRRQWUFuX3upfjQLjcSMwWxytvBbOh5vgWR+2YYg61J2jzK/LuaW7vCVCn1pThHGxq6r3h4/Ite5k9qZLiguRbw4rIyKDAEVd3d7DkSIYHx5N1VUHQtRRtcezvCRzJWxxjS4vYG7lz/NWt+yguyOPMumCZkJo+A+57mjt60qbXlgG9p+Q2tydYveOAuqlERIEjtsTQbBubahmPcWW9xyT2tSZfGTdUXVrEofYE7YmgRfG7N5qYPbmy5y7zIwPuwb0cTYfae2ZvTR1XilnvKbkvv7WPbgfzpo49niqKSA5Q4Igrw5s4QTg4njxwHNXiaAv34kgdOCBomWzYdYiNjc1ccU5dr/eDIGCEy42M82klhflMqhrdq8WxfPPbFOQZc07RjX8iI50CR1wZ3sQJwum4ybuqxpUV91paPVwZtyLF4Hh0ocMnVv2ZPIPLzz4SOGrLg2VHGg+19yw3ErY4AE6tKe3V4li+eS9nTajQwoYiosARW4b3G+/udrQeo8Wxv7WTjkSw7EiqlXFD0fWqnli1k/NOHdvTygjz8yxocYQBKZo/vbaMzXtaWL/rIAcPd/KnbRrfEJGA/nyMq6fFkaH9xv3U11SD42Fr4O2WduoqgoUIy4oLjloZNxQGjhcamti8p4Ub3jOtV35+njHWT8kNbwQcV3ak9XLOxEraE5tZ+O0XMAPnYN4UBQ4RUeCIL8Mtjtb25HtxhKJjEnUVo9jf1pGytQFHAseDK7ZRkGcsPOuko86p9cuOhMuN1ES6qv5yVh2njy9n/a6DbNzdzIG2Ti6YMW5glRORnKLAEVeGWxwtHeHuf6lmVQWBIOxWSrUybqhydBFmQZfWhafV9OzRERUuO7Knp8VxJHCYGaefVM7pJ2kxQxHpTWMccWW4xdGz33iKwfGwxREOWO9r7aAqxT0cEHRFhfkfmFWX9Jzw7vE9keVGRESORS2OuDI8HTcMHKlaHHUVo5g1sYKv/2o9hfl57G/tpK6y/yBWXVpE8+EElybppgK/XlVzMMYxtrSYvLyRvTOwiMSTlRaHmX3YzNaYWbeZ1UfSC83sXjN73czWmdmSSN5CM9tgZg1mdvOQFzrD03Fbwv3GUwSO/Dzj/r+dz4Izx3PrL9ayaU9L0pVxo945pYqr5kxI2ZKoLS8m0e3Y2Njcs9yIiMixZKurajVwFfD7PukfBoqdc+cAc4G/M7MpZpYP3A5cDswErjWzmUNZYDr9bnkZ66oK9xtPvQ5UaXEB3//oXBZfdCpw5F6MVP7jqll8/UOzUubX+Ndv2HWw1/iGiEh/stJV5ZxbBxy1YRHggFIzKwBGAR3AQWAe0OCc2+Rf9wDwQWDtUJU549NxO5JvG9tXXp7xz5edwftmnsS0mtLj+pnhuMnhzu5eM6pERPoz3AbHHwZagJ3AVuCbzrm9wARgW+S87T4tKTO7wcxWmtnKpqamwSlZZxtgUJCZL9jmnhZHvFh+7qRKxpQc32B29Ia/ceUKHCIST8ZaHGb2LJBsVPYW59xjKV42D+gCTgaqgBf8+6TFOXcncCdAfX29S/f1SYV7cRzdShoUPfdxpLgBMBNqo4FDLQ4RiSljgcM5t2AAL/sI8GvnXCfQaGZLgXqC1sakyHkTgR3HX8o0ZHgvjuaOBEUFeRQO4V7epcUFjC7Kp7Wjq9dd4yIi/RluXVVbgYsBzKwUmA+sB1YAM8xsqpkVAYuAx4e0ZBneNjbYxGnoN0gKu6tq1FUlIjFlazruX5vZduA84Ekze8pn3Q6UmdkagmBxj3NulXMuAXwWeApYBzzknFszpIXO0raxmRZ2V2lwXETiytasqkeAR5KkNxNMyU32ml8Cv8xw0VLLcFdVS0ci9sD4YApbGhrjEJG4hltX1fDV2ZrZrqqOriEdGA/VlpdQlJ+n5UZEJDYtORJXZxuUjMnY2ze3J1IuN5JJn75gKudPH6flRkQkNgWOuDrboDz5mk+DobW9q9f02KEyqXo0k6oz15ISkdyjrqq4Mjw43pylwXERkXQpcMQ1wMHx5vYEa/988JjntWZpcFxEJF0KHHEN8D6Orz2xliu/9yI79rf1e15LlgbHRUTSpcAR1wC6qva1dPDIqztIdDt+9Ictqd+6q5uORDdlanGIyAlAgSOOrk7o7ky7xfHQym20J7qZNbGCnyzf2rNZU1+tfoHDVHtxiIgMJwoccQxg29iubsePX3qL+dOqufXKszh0OMFPV25Lem5zR7j7n7qqRGT4U+CIYwCB47l1u9m+r41P/sUUZk+uYs7kSu5euoWu7mCx3o5ENxt3H8I5d2RlXHVVicgJQN9UcQxgE6d7/7iFkytKWHDmeACuf/c0PnPfKzyzdjflJQX822Or2dTUwuzJlbz/nDoAStXiEJETgFoccaTZ4mhoPMTShre5bv4pFPhl0i+dOZ6JVaP44sN/4rq7ltHV7fjH953Gn/e38bUn1wHxN3ESEckmfVPF0RM44rU4frJsG0UFeSx655EtRAry81h80XS+/PgablowgxsvPJWSwnyuf/c07l66mefW7WbG+PJMlF5EZFApcMTR01V17BaHc45n1u3iPTPGMbbPirPXzpvMh+dO7GmFAIwqymfxRdNZfNH0QS2yiEimqKsqjjRaHA2NzWzb28bFZ4xPml8whDv8iYhkgr7F4kjEH+N4bn0jABedUZPJEomIZI0CRxxpDI4/v66RmXVjqKvI3IKIIiLZpMARR8zpuPtbO1j51l4uObN2CAolIpIdChxxhC2OgpJ+T/vdG010O7j4DAUOEcldChxxxGxxPL++kbGlRbxjYuUQFEpEJDsUOOLobAPLh/zU+3Inurr57YYmLjqjVtuwikhOU+CII9yLw1IHhFe27udAWyeXqJtKRHKcAkccMfbieHbdbgrzjQtmjBuiQomIZIcCRxzH2Db24OFOHli+lfeeXkt5SeruLBGRXKDAEUdna78D4z9cuoWDhxN87pIZQ1goEZHsUOCII9Li6Op2OOd6sg60dXLXC5tYcOZ4zp5Qka0SiogMGQWOOPzg+J7mdq74zgv81e1L2bE/uLfjnqWbOXg4wU0L1NoQkZEhK4HDzP7LzNab2Soze8TMKiN5S8yswcw2mNllkfSFPq3BzG4e0gJ3ttKZX8LHfrCct/a2sKmphSu/+yJPr9nFD17czKUz1doQkZEjWy2OZ4CznXOzgDeAJQBmNhNYBJwFLAT+x8zyzSwfuB24HJgJXOvPHRJdHa2s2NHGm43N3PGxeh797PlUji7khh+/zKHDCW5acNpQFUVEJOuysh+Hc+7pyNOXgKv98QeBB5xz7cBmM2sA5vm8BufcJgAze8CfuzZTZdz41bkUunYAJnTvZHdXDbddO5sLTwtWvX108fn8+2NrqC4tYubJYzJVDBGRYWc4bOT0KeBBfzyBIJCEtvs0gG190t+V6g3N7AbgBoDJkycPqFAHSqeQ190BwF6mMqn+eurPPqknv7ykkG9dc+6A3ltE5ESWscBhZs8CJyXJusU595g/5xYgAdw3mD/bOXcncCdAfX29O8bpSdV/4WeDWSQRkZyRscDhnFvQX76ZfRL4AHCJOzK/dQcwKXLaRJ9GP+kiIjKEsjWraiHwReBK51xrJOtxYJGZFZvZVGAGsBxYAcwws6lmVkQwgP74UJdbRESyN8bxPaAYeMaChQNfcs7d6JxbY2YPEQx6J4DFzrkuADP7LPAUkA/c7Zxbk52ii4iMbBa9CzoX1dfXu5UrV2a7GCIiJwwze9k5V58qX3eOi4hIWhQ4REQkLQocIiKSFgUOERFJS84PjptZE/BWGi8ZB+zJUHGGq5FYZxiZ9R6JdYaRWe/jqfMpzrmaVJk5HzjSZWYr+5tNkItGYp1hZNZ7JNYZRma9M1lndVWJiEhaFDhERCQtChxHuzPbBciCkVhnGJn1Hol1hpFZ74zVWWMcIiKSFrU4REQkLQocIiKSFgUOz8wWmtkGM2sws5uzXZ7jYWaTzOw3ZrbWzNaY2ed8erWZPWNmG/2/VT7dzOw2X/dVZjYn8l6f8OdvNLNPZKtO6fD71L9qZk/451PNbJmv34N+aX788v0P+vRlZjYl8h5LfPoGM7ssOzWJx8wqzexhM1tvZuvM7LyRcK3N7PP+93u1md1vZiW5eK3N7G4zazSz1ZG0Qbu+ZjbXzF73r7nN/JLl/XLOjfgHwVLtbwLTgCLgT8DMbJfrOOpTB8zxx+XAG8BM4BvAzT79ZuA//fEVwK8AA+YDy3x6NbDJ/1vlj6uyXb8Y9f8C8BPgCf/8IWCRP/4+8Pf++DPA9/3xIuBBfzzT/w4UA1P970Z+tuvVT33vBa73x0VAZa5fa4ItpTcDoyLX+JO5eK2B9wBzgNWRtEG7vgR7Hs33r/kVcPkxy5TtD2U4PIDzgKciz5cAS7JdrkGs32PA+4ANQJ1PqwM2+OM7gGsj52/w+dcCd0TSe503HB8Eu0M+B1wMPOH/M+wBCvpea4L9Xc7zxwX+POt7/aPnDbcHUOG/QK1Pek5fax84tvkvwgJ/rS/L1WsNTOkTOAbl+vq89ZH0XueleqirKhD+Eoa2+7QTnm+SzwaWAeOdczt91i5gvD9OVf8T8XP5NsHukt3++Vhgv3Mu4Z9H69BTP59/wJ9/ItV7KtAE3OO75+4ys1Jy/Fo753YA3wS2AjsJrt3L5Pa1jhqs6zvBH/dN75cCRw4zszLgZ8BNzrmD0TwX/HmRU3OxzewDQKNz7uVsl2UIFRB0Y/yvc2420ELQddEjR691FfBBgsB5MlAKLMxqobIkG9dXgSOwA5gUeT7Rp52wzKyQIGjc55z7uU/ebWZ1Pr8OaPTpqep/on0u5wNXmtkW4AGC7qrvAJVmFm6THK1DT/18fgXwNidWvbcD251zy/zzhwkCSa5f6wXAZudck3OuE/g5wfXP5WsdNVjXd4c/7pveLwWOwApghp+RUUQwePZ4lss0YH5WxA+Adc65/45kPQ6Esyk+QTD2EaZ/3M/ImA8c8M3gp4BLzazK/4V3qU8blpxzS5xzE51zUwiu4fPOueuA3wBX+9P61jv8PK725zufvsjPxJkKzCAYQBx2nHO7gG1mdrpPugRYS45fa4IuqvlmNtr/vof1ztlr3cegXF+fd9DM5vvP8eOR90ot24M+w+VBMBvhDYJZFbdkuzzHWZcLCJquq4DX/OMKgj7d54CNwLNAtT/fgNt93V8H6iPv9SmgwT/+Jtt1S+MzeC9HZlVNI/gyaAB+ChT79BL/vMHnT4u8/hb/eWwgxiyTLNf1XGClv96PEsyayflrDdwKrAdWAz8mmBmVc9cauJ9gHKeToIX56cG8vkC9/wzfBL5Hn4kWyR5ackRERNKirioREUmLAoeIiKRFgUNERNKiwCEiImlR4BARkbQocIjEYGZdZvZa5NHvCspmdqOZfXwQfu4WMxt3vO8jMpg0HVckBjNrds6VZeHnbiGYi79nqH+2SCpqcYgcB98i+Ibfz2C5mU336V8xs3/yx/9gwd4oq8zsAZ9WbWaP+rSXzGyWTx9rZk9bsM/EXQQ3dIU/66P+Z7xmZndYsO9Ivpn90II9KV43s89n4WOQEUaBQySeUX26qq6J5B1wzp1DcNftt5O89mZgtnNuFnCjT7sVeNWn/SvwI5/+ZeBF59xZwCPAZAAzOxO4BjjfOXcu0AVcR3DX+ATn3Nm+DPcMYp1Fkio49ikiArT5L+xk7o/8+60k+auA+8zsUYIlQSBYFuZDAM65531LYwzBpj1X+fQnzWyfP/8SYC6wwm/QNopgYbtfANPM7LvAk8DTA6+iSDxqcYgcP5fiOPR+gvWD5hB88Q/kDzYD7nXOnesfpzvnvuKc2we8A/gtQWvmrgG8t0haFDhEjt81kX//GM0wszxgknPuN8C/ECznXQa8QNDVhJm9F9jjgj1Tfg98xKdfTrBgIQQL2l1tZrU+r9rMTvEzrvKccz8DvkQQnEQySl1VIvGMMrPXIs9/7ZwLp+RWmdkqoJ1g682ofOD/zKyCoNVwm3Nuv5l9Bbjbv66VI0tk3wrcb2ZrgD8QLB+Oc26tmX0JeNoHo05gMdBGsPtf+EfgksGrskhymo4rchw0XVZGInVViYhIWtTiEBGRtKjFISIiaVHgEBGRtChwiIhIWhQ4REQkLQocIiKSlv8HXgI+m8Ms8lEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}